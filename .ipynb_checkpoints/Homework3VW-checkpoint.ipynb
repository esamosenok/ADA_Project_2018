{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA 2018 - Homework 3\n",
    "\n",
    "\n",
    "\n",
    "## Undestanding the StackOverflow community\n",
    "\n",
    "\n",
    "Deadline: Nov 7th 2018, 23:59:59\n",
    "\n",
    "Submission link: Check channel homework-3-public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StackOverflow is the most popular programming-related Q&A website. It serves as a platform for users to ask and answer questions and to vote questions and answers up or down. Users of StackOverflow can earn reputation points and \"badges\"; for example, a person is awarded 10 reputation points for receiving an \"up\" vote on an answer given to a question, and 5 points for the \"up\" vote on a question asked. Also, users receive badges for their valued contributions, which represents a kind of gamification of the traditional Q&A site. \n",
    "\n",
    "[Learn more about StackOverflow on Wikipedia](https://en.wikipedia.org/wiki/Stack_Overflow)\n",
    "\n",
    "----\n",
    "\n",
    "Dataset link:\n",
    "\n",
    "https://drive.google.com/open?id=1POlGjqzw9v_pZ_bUnXGihOgk45kbvNjB\n",
    "\n",
    "http://iccluster053.iccluster.epfl.ch/Posts.json.zip (mirror 1)\n",
    "\n",
    "https://iloveadatas.com/datasets/Posts.json.zip (mirror 2)\n",
    "\n",
    "Dataset description:\n",
    "\n",
    "* **Id**: Id of the post\n",
    "* **CreationDate**: Creation date of the post (String format)\n",
    "* **PostTypeId**: Type of post (Question = 1, Answer = 2)\n",
    "* **ParentId**: The id of the question. Only present if PostTypeId = 2\n",
    "* **Score**: Points assigned by the users\n",
    "* **Tags**: Tags of the question. Only present if PostTypeId = 1\n",
    "* **Title**: Only present if PostTypeId = 1\n",
    "* **ViewCount**: Only present if PostTypeId = 1\n",
    "\n",
    "The dataset format is JSON. Here are examples of a question and an answer:\n",
    "\n",
    "Question:\n",
    "```json\n",
    "{\n",
    "    \"Id\": 10130734,\n",
    "    \"CreationDate\": \"2012-04-12T19:51:25.793+02:00\",\n",
    "    \"PostTypeId\": 1,\n",
    "    \"Score\": 4,\n",
    "    \"Tags\": \"<python><pandas>\",\n",
    "    \"Title\": \"Best way to insert a new value\",\n",
    "    \"ViewCount\": 3803\n",
    "}\n",
    "```\n",
    "\n",
    "Answer:\n",
    "```json\n",
    "{  \n",
    "   \"CreationDate\":\"2010-10-26T03:19:05.063+02:00\",\n",
    "   \"Id\":4020440,\n",
    "   \"ParentId\":4020214,\n",
    "   \"PostTypeId\":2,\n",
    "   \"Score\":1\n",
    "}\n",
    "```\n",
    "\n",
    "----\n",
    "Useful resources:\n",
    "\n",
    "**Spark SQL, DataFrames and Datasets Guide**\n",
    "\n",
    "https://spark.apache.org/docs/latest/sql-programming-guide.html\n",
    "\n",
    "**Database schema documentation for the public data dump**\n",
    "\n",
    "https://meta.stackexchange.com/questions/2677/database-schema-documentation-for-the-public-data-dump-and-sede\n",
    "\n",
    "----\n",
    "\n",
    "**Note:** Use Spark where possible. Some computations can take more than 10 minutes on a common notebook. Consider to save partial results on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your imports here\n",
    "import pandas as pd\n",
    "from pandas import *\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task A: Convert the dataset to a more convenient format\n",
    "As a warm-up task (and to avoid to warm up your laptop too much), load the dataset into a Spark dataframe, show the content, and save it in the _Parquet_ format. Use this step to convert the fields to a more convenient form.\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. How many questions have been asked on StackOverflow?\n",
    "2. How many answers have been given?\n",
    "3. What is the percentage of questions with a score of 0?\n",
    "\n",
    "**Hint:** The next tasks involve a time difference. Consider storing time in numeric format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "We read the data and switch the date from a string to a numerical representation. After that we write a parquet file to be able to access the data faster. Additionally we create a smaller subset of the data for testing purposes, after which we show the schema of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We start by reading the data into a dataframe and saving it in the parquet format. You only need to do this once\n",
    "#df = spark.read.json(\"data/Posts.json\")\n",
    "df = spark.read.csv(\"data/countries_list.csv\")\n",
    "#timestamp = to_timestamp(df[\"CreationDate\"])\n",
    "#df = df.withColumn(\"CreationDate\", timestamp)\n",
    "#df.write.parquet(\"df.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CreationDate: timestamp (nullable = true)\n",
      " |-- Id: long (nullable = true)\n",
      " |-- ParentId: long (nullable = true)\n",
      " |-- PostTypeId: long (nullable = true)\n",
      " |-- Score: long (nullable = true)\n",
      " |-- Tags: string (nullable = true)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- ViewCount: long (nullable = true)\n",
      "\n",
      "+--------------------+--------+--------+----------+-----+--------------------+--------------------+---------+\n",
      "|        CreationDate|      Id|ParentId|PostTypeId|Score|                Tags|               Title|ViewCount|\n",
      "+--------------------+--------+--------+----------+-----+--------------------+--------------------+---------+\n",
      "|2017-08-17 16:20:...|45740344|45740224|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:20:...|45740346|45739185|         2|    1|                null|                null|     null|\n",
      "|2017-08-17 16:20:...|45740348|    null|         1|    2|<flash><react-nat...|Is it possible to...|      143|\n",
      "|2017-08-17 16:20:...|45740350|45739102|         2|    1|                null|                null|     null|\n",
      "|2017-08-17 16:20:...|45740352|42473616|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:20:...|45740354|45668191|         2|    1|                null|                null|     null|\n",
      "|2017-08-17 16:20:...|45740355|    null|         1|    1|<postgresql><form...|Remove trailing z...|      444|\n",
      "|2017-08-17 16:21:...|45740357|44484201|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740358|    null|         1|    0|<python><websocke...|Python websockets...|      280|\n",
      "|2017-08-17 16:21:...|45740359|19922107|         2|    4|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740361|45740273|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740363|    null|         1|    0|<facebook><facebo...|Image meta tag no...|       97|\n",
      "|2017-08-17 16:21:...|45740367|45725024|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740369|45724556|         2|    1|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740370|45739756|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740371|    null|         1|    1|    <mongodb><shell>|Using Mongo-cli t...|      185|\n",
      "|2017-08-17 16:21:...|45740372|    null|         1|    0|            <impala>|Impact of \"INVALI...|      327|\n",
      "|2017-08-17 16:21:...|45740374|45739780|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740375|45721970|         2|    0|                null|                null|     null|\n",
      "|2017-08-17 16:21:...|45740376|45740035|         2|    1|                null|                null|     null|\n",
      "+--------------------+--------+--------+----------+-----+--------------------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Read the parquet and have a look at the schema\n",
    "df = spark.read.parquet(\"df.parquet\")\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce dataset for testing purposes. Only execute the cell if you want to work on a subset\n",
    "sub = spark.createDataFrame(df.take(10000))\n",
    "#df = sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For question one we want the amount of quesions on stackoverflow, so we simply filter by the ID corresponding to questions and count the matching rows.\n",
    "\n",
    "For question two the process is the same, only using the ID for answers\n",
    "\n",
    "For question three we filter the questions by score == 0. A simple division then gives us the percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15647060 questions have been asked\n",
      "25192772 answers have been provided\n",
      "0.46543657402732524 is the percentage of questions with score 0\n"
     ]
    }
   ],
   "source": [
    "questions = df.filter(df['PostTypeId'] == 1)\n",
    "print(\"{} questions have been asked\".format(questions.count()))\n",
    "\n",
    "answers = df.filter(df['PostTypeId'] == 2)\n",
    "print(\"{} answers have been provided\".format(answers.count()))\n",
    "\n",
    "zero_questions = questions.filter(questions['score'] == 0)\n",
    "print(\"{} is the percentage of questions with score 0\".format(zero_questions.count()/questions.count()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** Load the dataset from the Parquet file for the next tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task B: What are the 10 most popular tags?\n",
    "\n",
    "What are the most popular tags in StackOverflow? Use Spark to extract the information you need, and answer the following questions with Pandas and Matplotlib (or Seaborn):\n",
    "\n",
    "1. What is the proportion of tags that appear in fewer than 100 questions?\n",
    "2. Plot the distribution of the tag counts using an appropriate representation.\n",
    "3. Plot a bar chart with the number of questions for the 10 most popular tags.\n",
    "\n",
    "For each task describe your findings briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "To prepare the data we extract the tags column and remove the nans before splitting each string into its component tags.\n",
    " \n",
    "Having done that we group the tags by their name, counting how many times each tag appears and sorting the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch to rdd\n",
    "rdd = df.rdd\n",
    "\n",
    "#Remove nans\n",
    "rdd = rdd.filter(lambda row: row.Tags != None)\n",
    "\n",
    "#Split on >< in tags\n",
    "rdd = rdd.flatMap(lambda row: [(x,) for x in (row.Tags[1:-1].split('><'))])\n",
    "\n",
    "#Regenerate the dataframe\n",
    "df2 = rdd.toDF()\n",
    "\n",
    "#Group by the tag names\n",
    "tags = df2.groupBy(\"_1\").count()\n",
    "\n",
    "#Sort the dataframe\n",
    "tags = tags.sort(\"count\", ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve question one we check how many distinct tags there are as well as how many tags appear fewer than 100 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8fcd0779ada0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Count total amount of tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Count amount of tags appearing less than 100 times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0munpopular\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcount\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \"\"\"\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Count total amount of tags\n",
    "total = tags.count()\n",
    "\n",
    "#Count amount of tags appearing less than 100 times\n",
    "unpopular = tags.filter(tags[\"count\"] < 100).count()\n",
    "\n",
    "#Calculate proportion\n",
    "print(\"There are {} tags, of which {} appears less than 100 times, giving us a ratio of {}\".format(total, unpopular, unpopular/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve question two, we convert the tags table to a pandas dataframe since it's relatively small, and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdt = tags.toPandas()\n",
    "ax = pdt.plot.hist(bins = 50, figsize=[15,5],color='orange')\n",
    "ax.set_title(\"The relation between amount of tags and amount of questions\")\n",
    "ax.set_xlabel('Number of tags')\n",
    "ax.set_ylabel('Amount of questions (log)')\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final question we simply show the top ten rows in our table, since we already sorted it on how many times the tag appears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract top 10 categories\n",
    "tag_counts = pdt.rename(columns=({'_1':'Tag'}))\n",
    "display(tag_counts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task C: View-score relation\n",
    "\n",
    "We want to investigate the correlation between the view count and the score of questions.\n",
    "\n",
    "1. Get the view count and score of the questions with tag ```random-effects``` and visualize the relation between these two variables using an appropriate plot.\n",
    "2. Are these two variables correlated? Use the Pearson coefficient to validate your hypothesis. Discuss your findings in detail.\n",
    "\n",
    "**Hint:** Inspect the data visually before drawing your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach\n",
    "\n",
    "We register the DataFrame as a SQL temporary view and extracts viewcount and score in all questions with the correct tag. After that we explore the (eventual) correlation via a small battery of graphs and tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Allow SQL queries to be executed\n",
    "questions.createOrReplaceTempView(\"questions\")\n",
    "\n",
    "#Extract the relevant information\n",
    "sqlDF = spark.sql(\"SELECT ViewCount, Score \\\n",
    "                  FROM questions \\\n",
    "                  WHERE Tags \\\n",
    "                  LIKE '%random-effects%'\")\n",
    "\n",
    "#Convert it into a pandas dataframe. Because I like them.\n",
    "random = sqlDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(random.describe())\n",
    "random.plot.scatter(x = 'ViewCount', y = 'Score', figsize=[15,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look as if they are pretty correlated, though some outliers could be skewing the result.\n",
    "\n",
    "Calculating the  Pearson coefficient, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we have a pretty strong positive linear correlation. With that being said Pearsons is sensitive to outliers of which we appear to have two, based on the scatterplot. Bootstrapping could be an idea to create confidence intervals for our measurments, but it's likely easier to simply remove the outliers and check again. By sorting the values and checking the extremes we get an idea of what values to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(random.sort_values(by=\"ViewCount\", ascending=False).head(5))\n",
    "display(random.sort_values(by=\"Score\", ascending=False).head(5))\n",
    "\n",
    "rando = random.drop(index=[95,79])\n",
    "rando.reset_index()\n",
    "\n",
    "display(rando.corr())\n",
    "\n",
    "rando.plot.scatter(x = 'ViewCount', y = 'Score', figsize=[15,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by removing the two outliers, the pearson score was reduced quite significantly from 0.882197 to 0.439389, a result mirrored in the look of our scatterplot.\n",
    "\n",
    "What we're really checking with this analysis is if there is a linear relationship between the popularity (amount of views) of a problem and the usefullness of the answer (score). While it's reasonable to expect some relationship between the two (the more people who suffer from a problem the more will try to create a good answer to a problem), it's not necessarily a strong one. The fact that you have to be a member to add a score to a solution, but you don't have to be one to view a problem already skews the relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task D: What are the tags with the fastest first answer?\n",
    "\n",
    "What are the tags that have the fastest response time from the community? We define the response time as the difference in seconds between the timestamps of the question and of the first answer received.\n",
    "\n",
    "1. Get the response time for the first answer of the questions with the tags ```python``` and ```java```.\n",
    "2. Plot the two distributions in an appropriate format. What do you observe? Describe your findings and discuss the following distribution properties: mean, median, standard deviation.\n",
    "3. We believe that the response time is lower for questions related to Python (compare to Java). Contradict or confirm this assumption by estimating the proper statistic with bootstrapping. Visualize the 95% confidence intervals with box plots and describe your findings.\n",
    "3. Repeat the first analysis (D1) by using the proper statistic to measure the response time for the tags that appear at least 5000 times. Plot the distribution of the 10 tags with the fastest response time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach q1 q2\n",
    "We use sql queries to extract all rows with the python/java tag, separating them into questions and answers.\n",
    "After that we join them on the id to match each questions with its answers, select the fastest answer and plot the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PYTHON\n",
    "#Allow SQL queries to be executed\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "#Extract questions with the python tag\n",
    "py_q = spark.sql(\"SELECT CreationDate as q_date, Id \\\n",
    "                  FROM df \\\n",
    "                  WHERE Tags \\\n",
    "                  LIKE '%<python>%'\\\n",
    "                  AND PostTypeId = 1\\\n",
    "                  AND CreationDate IS NOT null\")\n",
    "\n",
    "#Extract answers\n",
    "py_a = spark.sql(\"SELECT CreationDate as a_date, ParentId \\\n",
    "                  FROM df \\\n",
    "                  WHERE PostTypeId = 2 \\\n",
    "                  AND CreationDate IS NOT null\")\n",
    "\n",
    "\n",
    "#Inner join where the question id = answer parent id\n",
    "py_qa = py_q.join(py_a, py_q.Id == py_a.ParentId)\n",
    "\n",
    "#Calculate time elapsed between the answer and the question\n",
    "diff = unix_timestamp(py_qa.a_date) - unix_timestamp(py_qa.q_date)\n",
    "py_qa = py_qa.withColumn(\"difference\", diff)\n",
    "\n",
    "#If the calculated difference is below something is wrong with that row, so we drop them\n",
    "py_qa = py_qa.filter(py_qa.difference > 0)\n",
    "\n",
    "#Group by the Parent Id, selecting only the lowest values to get the fastest answers\n",
    "py_qa = py_qa.groupBy(\"Id\").agg(min(\"difference\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JAVA\n",
    "#Allow SQL queries to be executed\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "#Extract questions with the python tag\n",
    "j_q = spark.sql(\"SELECT CreationDate as q_date, Id \\\n",
    "                  FROM df \\\n",
    "                  WHERE Tags \\\n",
    "                  LIKE '%<java>%'\\\n",
    "                  AND PostTypeId = 1\\\n",
    "                  AND CreationDate IS NOT null\")\n",
    "\n",
    "#Extract answers\n",
    "j_a = spark.sql(\"SELECT CreationDate as a_date, ParentId \\\n",
    "                  FROM df \\\n",
    "                  WHERE PostTypeId = 2 \\\n",
    "                  AND CreationDate IS NOT null\")\n",
    "\n",
    "\n",
    "#Inner join where the question id = answer parent id\n",
    "j_qa = j_q.join(j_a, j_q.Id == j_a.ParentId)\n",
    "\n",
    "#Calculate time elapsed between the answer and the question\n",
    "diff = unix_timestamp(j_qa.a_date) - unix_timestamp(j_qa.q_date)\n",
    "j_qa = j_qa.withColumn(\"difference\", diff)\n",
    "\n",
    "#If the calculated difference is below something is wrong with that row, so we drop them\n",
    "j_qa = j_qa.filter(j_qa.difference > 0)\n",
    "\n",
    "#Group by the Parent Id, selecting only the lowest values to get the fastest answers\n",
    "j_qa = j_qa.groupBy(\"Id\").agg(min(\"difference\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to dataframes for ease of plotting.\n",
    "j_df = j_qa.toPandas()\n",
    "py_df = py_qa.toPandas()\n",
    "\n",
    "#Plot the two distributions\n",
    "ax = j_df['min(difference)'].hist(alpha=0.5, bins = 50, figsize=[15,5], color = 'blue', grid=True, )\n",
    "ax = py_df['min(difference)'].hist(alpha=0.5, bins = 50, color = 'green')\n",
    "ax.set_title(\"Questions and response times for java (blue) and python (green)\")\n",
    "ax.set_xlabel('Response time (seconds)')\n",
    "ax.set_ylabel('Amount of answers (log)')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "#Extract the stats for the distributions\n",
    "j = j_df[['min(difference)']].describe()\n",
    "p = py_df[['min(difference)']].describe()\n",
    "\n",
    "#Join them and display them in one table\n",
    "j = j.rename(columns={\"min(difference)\": \"Java stats\"})\n",
    "p = p.rename(columns={\"min(difference)\": \"Python stats\"})\n",
    "display(j.join(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution looks like it could be log-linear if you exclude the proportion of answers which are provided practically immediatly. The standard deviation is about the same for both distributions which is reflected in the rather similar layout of the two. The average (mean) waiting time is quite horrible at around 11 days, while the median for the two ends up signifying around half an hour, reflective of the fact that most questions are quickly answered while a small amount of datapoints drags the mean out. Even looking at the 75/% percentile most questions are answered within a couple of hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach q3\n",
    "Matplotlib has bootstrapping for 95% confidence intervals for the mean built in [link](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.boxplot.html). Applying that functionality to our two vectors of response time we can thus compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the response times\n",
    "j_resp = j_df['min(difference)']\n",
    "p_resp = py_df['min(difference)']\n",
    "\n",
    "#Convert to np arrays\n",
    "data = [np.array(j_resp), np.array(p_resp)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the two boxplots using bootstrapping. Bootstrap should be between 1000 and 10000 for a 95% CI\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.boxplot(data, notch = True, bootstrap=100, widths=0.95, sym='')\n",
    "ax.set_xticklabels(['Java', 'Python']);\n",
    "\n",
    "ax.set_ylabel('Response time (seconds)');\n",
    "ax.set_title(\"Comparison of response times\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence intervals are displayed as notches in the boxes around the orange line. Notably, we don't really see the notches because the bounds appear to be very tight. Looking at the median (the orange line) and comparing the boxplots we would not claim that Python is faster than Java and state that the differences between the two are negligble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach q4\n",
    "We get all tags that appear more than 5000 times. Then, for each tag, we get the fastest response for each question with that tag. Then we compute the median for that tag, giving as a list of the median for each tag. We the plot this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get each tag that appears more than 5000 times. Save them so we don't have to execute the query again\n",
    "popular = tags.filter(tags[\"count\"] > 5000)\n",
    "popular.write.parquet(\"popular.parquet\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get all tags that appear more than 5000 times and store them in a panda dataframe\n",
    "popular = spark.read.parquet(\"popular.parquet\")\n",
    "pop = popular.toPandas()\n",
    "pop = pop.rename(columns={\"_1\":\"tag\"})\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each tag in the frame, get all the questions in which it appear and the fastest answer to each question.\n",
    "\n",
    "#List to store the results for each tag\n",
    "medians = []\n",
    "counter = 0\n",
    "for tag in pop['tag']:\n",
    "    print(\"{}/1096 done\".format(counter))\n",
    "    counter += 1\n",
    "    \n",
    "    #Allow SQL queries to be executed\n",
    "    df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "    #Extract questions with the tag\n",
    "    t_q = spark.sql(\"SELECT CreationDate as q_date, Id \\\n",
    "                      FROM df \\\n",
    "                      WHERE Tags \\\n",
    "                      LIKE '%<\" + tag + \">%'\\\n",
    "                      AND PostTypeId = 1\\\n",
    "                      AND CreationDate IS NOT null\")\n",
    "\n",
    "    #Extract answers\n",
    "    t_a = spark.sql(\"SELECT CreationDate as a_date, ParentId \\\n",
    "                      FROM df \\\n",
    "                o      WHERE PostTypeId = 2 \\\n",
    "                      AND CreationDate IS NOT null\")\n",
    "\n",
    "\n",
    "    #Inner join where the question id = answer parent id\n",
    "    t_qa = t_q.join(t_a, t_q.Id == t_a.ParentId)\n",
    "\n",
    "    #Calculate time elapsed between the answer and the question\n",
    "    diff = unix_timestamp(t_qa.a_date) - unix_timestamp(t_qa.q_date)\n",
    "    t_qa = t_qa.withColumn(\"difference\", diff)\n",
    "\n",
    "    #If the calculated difference is below something is wrong with that row, so we drop them\n",
    "    t_qa = t_qa.filter(t_qa.difference > 0)\n",
    "\n",
    "    #Group by the Parent Id, selecting only the lowest values to get the fastest answers\n",
    "    t_qa = t_qa.groupBy(\"Id\").agg(min(\"difference\"))\n",
    "    \n",
    "    #Get the median, store it\n",
    "    median = t_qa.approxQuantile('min(difference)', [0.5], 0)\n",
    " \n",
    "    #store it\n",
    "    medians.append(median[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is only to be used if we want to check a subset due to a limited time\n",
    "pop = pop.head(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We attach the medians that correspond to each tag to our dataframe\n",
    "pop['medians'] = Series(medians)\n",
    "\n",
    "#Sort on median response time\n",
    "pop = pop.sort_values(['medians', 'count'])\n",
    "\n",
    "#Extract top 10\n",
    "top10 = pop.head(10)\n",
    "\n",
    "#Plot it\n",
    "ax = top10[['medians','tag']].plot.bar(x='tag', figsize=[15,5], rot=45, color = 'orange')\n",
    "ax.set_title(\"Popular tags and how fast they are answered\")\n",
    "_ = ax.set_ylabel('median delay until first answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are sadly only partial. We started recreating them too late, so now the graph only consists of top10 of 34 of the around 1000 tags.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task E: What's up with PySpark?\n",
    "The number of questions asked regarding a specific topic reflect the publicâ€™s interest on it. We are interested on the popularity of PySpark. Compute and plot the number of questions with the ```pyspark``` tag for 30-day time intervals. Do you notice any trend over time? Is there any correlation between time and number of questions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract all questions with the pyspark tag\n",
    "\n",
    "#Allow SQL queries to be executed\n",
    "df.createOrReplaceTempView(\"df\")\n",
    "\n",
    "#Extract questions with the python tag\n",
    "pys = spark.sql(\"SELECT CreationDate as q_date, Id \\\n",
    "                  FROM df \\\n",
    "                  WHERE Tags \\\n",
    "                  LIKE '%<pyspark>%'\\\n",
    "                  AND PostTypeId = 1\\\n",
    "                  AND CreationDate IS NOT null\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order the questions by time, least first\n",
    "pys = pys.orderBy('q_date')\n",
    "\n",
    "pys.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pys.select(\"q_date\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "while i < 10:\n",
    "    date1=z[i]\n",
    "    while j < 10:\n",
    "        date2 = z[j]\n",
    "        j = j + 1\n",
    "        print(\"i = {} j = {}\".format(i, j)\n",
    "    i = i + 1\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 1\n",
    "while i < 10:\n",
    "    d1 = z[i]\n",
    "    while j < 10:\n",
    "        d2 = z[j]\n",
    "        print(i)\n",
    "        i += 1\n",
    "        j += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
